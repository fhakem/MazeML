{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IA318 - Reinforcement Learning\n",
    "\n",
    "# Dynamic programming\n",
    "\n",
    "This notebook presents techniques of dynamic programming (**policy iteration, value iteration**) for Tic-Tac-Toe and Nim.\n",
    "\n",
    "Do **not** attempt to apply this to Connect Four as the number of states is huge ($> 10^{12}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import TicTacToe, Nim, Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from display import display_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to encode states to form sets of states (not allowed with numpy arrays)\n",
    "def encode(state):\n",
    "    player, board = state\n",
    "    if player == 1:\n",
    "        return b'\\x01' + board.tostring()\n",
    "    else:\n",
    "        return b'\\x00' + board.tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(state_byte, shape):\n",
    "    player_byte = state_byte[0]\n",
    "    if player_byte:\n",
    "        player = 1\n",
    "    else:\n",
    "        player = -1\n",
    "    board_byte = state_byte[1:]\n",
    "    board = np.frombuffer(board_byte, dtype=int).reshape(shape)\n",
    "    return player, board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    \"\"\"Evaluation of a policy for a game.\n",
    "    \"\"\"\n",
    "    def __init__(self, Game, first_player=True, policy_player=None, policy_adversary=None, n_iter=10):\n",
    "        self.set_game(Game, first_player)\n",
    "        self.get_policies(policy_player, policy_adversary)\n",
    "        self.get_states()\n",
    "        self.state_id = {encode(state): i for i, state in enumerate(self.states)}\n",
    "        self.get_transition_matrix()\n",
    "        self.get_rewards()\n",
    "        self.get_values(n_iter)\n",
    "\n",
    "    def set_game(self, Game, first_player):\n",
    "        self.game = Game(first_player)\n",
    "        self.state = self.game.state\n",
    "        self.shape = self.state[1].shape\n",
    "        \n",
    "    def get_policies(self, policy_player, policy_adversary):\n",
    "        self.policy_player = Agent(self.game, policy_player).policy\n",
    "        self.policy_adversary = Agent(self.game, policy_adversary).policy\n",
    "        \n",
    "    def get_transitions(self, state):\n",
    "        probs = []\n",
    "        states = []\n",
    "        if not self.game.is_terminal(state):\n",
    "            player, board = state\n",
    "            if player == 1:\n",
    "                policy = self.policy_player\n",
    "            else:\n",
    "                policy = self.policy_adversary\n",
    "            for prob, action in zip(*policy(state)):\n",
    "                probs_, states_ = self.game.get_transition(state, action)\n",
    "                probs += list(prob * np.array(probs_))\n",
    "                states += states_\n",
    "        return probs, states\n",
    "    \n",
    "    def get_states(self):   \n",
    "        state_set = set()\n",
    "        state = self.state\n",
    "        state_set.add(encode(state))\n",
    "        state_explore = list(state_set)\n",
    "        while len(state_explore):\n",
    "            state_byte = state_explore.pop()\n",
    "            state = decode(state_byte, self.shape)\n",
    "            _, states = self.get_transitions(state)\n",
    "            if len(states):\n",
    "                state_add_set = {encode(state) for state in states}\n",
    "                state_explore += list(state_add_set - state_set)\n",
    "                state_set |= state_add_set\n",
    "        self.states = [decode(state_byte, self.shape) for state_byte in state_set]\n",
    "\n",
    "    def get_transition_matrix(self):    \n",
    "        n = len(self.states)\n",
    "        row = []\n",
    "        col = []\n",
    "        data = []\n",
    "        for i, state in enumerate(self.states):\n",
    "            probs, states = self.get_transitions(state)\n",
    "            indices = [self.state_id[encode(state_)] for state_ in states]\n",
    "            row += len(indices) * [i]\n",
    "            col += indices\n",
    "            data += probs\n",
    "        self.transition = sparse.csr_matrix((data, (row, col)), shape=(n, n))\n",
    "\n",
    "    def get_rewards(self):\n",
    "        self.rewards = [self.game.get_reward(state) for state in self.states]\n",
    "    \n",
    "    def get_values(self, n_iter):\n",
    "        n = len(self.states)\n",
    "        values = np.zeros(n)\n",
    "        rewards = np.array(self.rewards)\n",
    "        for t in range(n_iter):\n",
    "            values = self.transition.dot(rewards + values)\n",
    "        self.values = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chari\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\chari\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "evaluation = Evaluation(Nim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chari\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\chari\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "evaluation = Evaluation(TicTacToe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5478"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5478"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "Find the optimal way to play each game using policy iteration or value iteration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_policy(evaluation):\n",
    "    n, m = evaluation.shape\n",
    "    values = evaluation.values\n",
    "    rewards = evaluation.rewards\n",
    "    gamma = evaluation.gamma\n",
    "    best_actions = []\n",
    "    for i in range(n * m):\n",
    "        state = np.array([i // m, i % m])\n",
    "        if maze.is_valid(state):\n",
    "            actions = maze.get_actions(state)\n",
    "            rewards_actions = []\n",
    "            for action in actions:\n",
    "                probs, states = maze.get_transition(state, action)\n",
    "                indices = [state_[0] * m + state_[1] for state_ in states]\n",
    "                rewards_actions.append(np.sum(np.array(probs) * (rewards + gamma * values)[indices]))\n",
    "            best_actions.append(actions[np.argmax(rewards_actions)])\n",
    "        else:\n",
    "            best_actions.append((0, 0))\n",
    "    # policy(state) -> probs, actions\n",
    "    policy = lambda state: [[1], [best_actions[state[0] * m + state[1]]]]\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
